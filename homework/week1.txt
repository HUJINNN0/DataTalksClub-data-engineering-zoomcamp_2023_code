week1 - sql
quesion 1
$ docker build --help
----iidfile string

quesion 2
$ docker run -it --entrypoint=bash python:3.9
$ pip list 
--3

quesion 3

SELECT CAST(lpep_pickup_datetime AS date) as date, 
CAST(lpep_dropoff_datetime AS date) as date,
count(1)
FROM green_taxi_trips
WHERE CAST(lpep_pickup_datetime AS date) = '2019-01-15' and 
CAST(lpep_dropoff_datetime AS date) = '2019-01-15'
group by date;

--20530

quesion 4

SELECT CAST(lpep_pickup_datetime AS DATE) as "date", max(trip_distance) as "total_distance"
FROM green_taxi_trips
GROUP BY CAST(lpep_pickup_datetime AS DATE)
ORDER BY "total_distance" DESC;
--2019-01-15

quesion 5

SELECT passenger_count, count(*)
FROM green_taxi_trips
WHERE CAST(lpep_pickup_datetime as DATE) = '2019-01-01' AND passenger_count = 2
GROUP BY passenger_count
UNION ALL
SELECT passenger_count, count(*)
FROM green_taxi_trips
WHERE CAST(lpep_pickup_datetime as DATE) = '2019-01-01' AND passenger_count = 3
GROUP BY passenger_count;
--2: 1282 ; 3: 254

quesion 6

SELECT z."Zone" as "PU", z1."Zone" as "DO", MAX(tip_amount)
FROM green_taxi_trips t left join zones z
	on t."PULocationID" = z."LocationID"
	left join zones z1 
	on t."DOLocationID" = z1."LocationID"
WHERE z."Zone" = 'Astoria'
GROUP BY z."Zone", z1."Zone"
ORDER BY max(tip_amount) DESC;

--Long Island City/Queens Plaza 

week1 - terraform
$ terraform apply
var.project
  Your GCP Project ID

  Enter a value: dtc-de-xxx


Terraform used the selected providers to generate the following execution
plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_bigquery_dataset.dataset will be created
  + resource "google_bigquery_dataset" "dataset" {
      + creation_time              = (known after apply)
      + dataset_id                 = "trips_data_all"
      + delete_contents_on_destroy = false
      + etag                       = (known after apply)
      + id                         = (known after apply)
      + labels                     = (known after apply)
      + last_modified_time         = (known after apply)
      + location                   = "europe-west6"
      + project                    = "dtc-de-xxx"
      + self_link                  = (known after apply)

      + access {
          + domain         = (known after apply)
          + group_by_email = (known after apply)
          + role           = (known after apply)
          + special_group  = (known after apply)
          + user_by_email  = (known after apply)

          + dataset {
              + target_types = (known after apply)

              + dataset {
                  + dataset_id = (known after apply)
                  + project_id = (known after apply)
                }
            }

          + routine {
              + dataset_id = (known after apply)
              + project_id = (known after apply)
              + routine_id = (known after apply)
            }

          + view {
              + dataset_id = (known after apply)
              + project_id = (known after apply)
              + table_id   = (known after apply)
            }
        }
    }

  # google_storage_bucket.data-lake-bucket will be created
  + resource "google_storage_bucket" "data-lake-bucket" {
      + force_destroy               = true
      + id                          = (known after apply)
      + location                    = "EUROPE-WEST6"
      + name                        = "dtc_data_lake_dtc-de-375802"
      + project                     = (known after apply)
      + public_access_prevention    = (known after apply)
      + self_link                   = (known after apply)
      + storage_class               = "STANDARD"
      + uniform_bucket_level_access = true
      + url                         = (known after apply)

      + lifecycle_rule {
          + action {
              + type = "Delete"
            }

          + condition {
              + age                   = 30
              + matches_prefix        = []
              + matches_storage_class = []
              + matches_suffix        = []
              + with_state            = (known after apply)
            }
        }

      + versioning {
          + enabled = true
        }

      + website {
          + main_page_suffix = (known after apply)
          + not_found_page   = (known after apply)
        }
    }

Plan: 2 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

google_bigquery_dataset.dataset: Creating...
google_storage_bucket.data-lake-bucket: Creating...
google_bigquery_dataset.dataset: Creation complete after 2s [id=projects/dtc-de-375802/datasets/trips_data_all]
google_storage_bucket.data-lake-bucket: Creation complete after 3s [id=dtc_data_lake_dtc-de-375802]

Apply complete! Resources: 2 added, 0 changed, 0 destroyed.

